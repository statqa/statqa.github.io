<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Are Large Language Models Good Statisticians?</title>
  <script type="module" src="https://md-block.verou.me/md-block.js"></script>


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://github.com/HKUSTDial">
      <span class="icon">
          <!-- <i class="fas fa-home"></i> -->
          <img src="static/favicon.png" alt="Home" />
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research @ HKUST(GZ)-DIAL
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/HKUSTDial">
            HKUST(GZ) DIAL
          </a>
          <!-- <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape -->
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Are Large Language Models Good Statisticians?</h1>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://derrickzhuyz.github.io/">Yizhang Zhu</a><sup>1</sup>,</span>
            <span class="author-block">
              Shiyin Du<sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://liboyan.vip/">Boyan Li</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://luoyuyu.vip/">Yuyu Luo</a><sup>1,2‚úâÔ∏è</sup>,
            </span>
            <span class="author-block">
              <a href="https://nantang.github.io/">Nan Tang</a><sup>1,2‚úâÔ∏è</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The Hong Kong University of Science and Technology (Guangzhou),</span>
            <span class="author-block"><sup>2</sup>The Hong Kong University of Science and Technology</span>
          </div>

          <div class="is-size-5 publication-authors">
            </strong><span class="author-block" style="color: rgb(145, 107, 164); font-weight: bold;">NeurIPS 2024 (D&B)üéâ</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2406.07815"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2406.07815"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/HKUSTDial/StatQA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/HKUSTDial/StatQA/tree/main/StatQA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="hero teaser">
  <div class="container is-max-desktop">
      <!-- <img id="teaser" autoplay muted loop playsinline height="100%" src="./static/images/human_statistician_thinking.png"/> -->
      <img id="teaser" autoplay muted loop playsinline height="90%" src="static\images\StatQA_cover.png"/>
      <h2 class="subtitle has-text-centered">
        Statistical Analysis Task and StatQA Construction
      </h2>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-wdith">
        <h2 class="title is-2">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            Large Language Models (LLMs) have demonstrated impressive capabilities across a range of scientific tasks including 
            mathematics, physics, and chemistry. Despite their successes, the effectiveness of LLMs in handling complex statistical 
            tasks remains systematically under-explored. To bridge this gap, we introduce <strong>StatQA</strong>, a new benchmark designed for 
            statistical analysis tasks. StatQA comprises 11,623 examples tailored to evaluate LLMs' proficiency in specialized 
            statistical tasks and their applicability assessment capabilities, particularly for hypothesis testing methods. 
          </p>
          <p>  
            We systematically experiment with representative LLMs using various prompting strategies and show that even state-of-the-art 
            models such as GPT-4o achieve a best performance of only 64.83%, indicating significant room for improvement. Notably, 
            while open-source LLMs (<i>e.g.</i> LLaMA-3) show limited capability, those fine-tuned ones exhibit marked improvements, 
            outperforming all in-context learning-based methods (<i>e.g.</i> GPT-4o).Moreover, our comparative human experiments highlight 
            a striking contrast in error types between LLMs and humans: LLMs primarily make applicability errors, whereas humans mostly 
            make statistical task confusion errors. This divergence highlights distinct areas of proficiency and deficiency, suggesting 
            that combining LLM and human expertise could lead to complementary strengths, inviting further investigation into their 
            collaborative potential.
          </p>
          <p>Our contributions are summarized as follows:</p>
          <md-block>
            - <strong>StatQA.</strong> We propose StatQA, a new benchmark for statistical analysis tasks, particularly focusing
            on the applicability assessment of statistical methods. We introduce an automated pipeline to
            construct StatQA by synthesizing statistical tasks and their corresponding answers, which also
            provides insights for dataset construction in other specialized domains with scarce examples.
            - <strong>Systematic Evaluation.</strong> We conduct extensive evaluations on widely used LLMs to establish
            benchmarks for statistical tasks. We also explore several strategies, including domain-specific
            prompts and fine-tuning, to better harness the capabilities of LLMs for these tasks.
            - <strong>Comparative Study between Humans and LLMs.</strong> We organize group-based human experiments
            and comparatively analyze differences between humans and LLMs in performance and
            errors. Our findings highlight humans' and LLMs' distinct strengths and weaknesses and reveal
            their potential complementarity.
            - <strong>New Empirical Findings and Research Opportunities.</strong> Based on the experiments and analysis
            above, we summarize six key findings and discuss research opportunities in this field.
          </md-block>
          <!-- <p>&ensp;</p>
          <div class="container is-max-desktop">
            <img id="teaser" autoplay muted loop playsinline height="100%" src="./static/images/human_statistician_thinking.png"/>
            <h5 class="subtitle has-text-centered">
              An Example of Statistical Analysis Task
            </h5>
          </div> -->
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>



<!-- StatQA construction  -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-2">StatQA Construction</h2>
        <p>&ensp;</p>
        <div class="columns is-centered">
          <div class="content has-text-justified">
            <md-block>
              In conventional dataset construction, researchers collect a suitable dataset D, formulate a question Q, 
              and manually annotate answers A. While this method ensures high data quality, it is time-consuming, costly, 
              and limits extensibility, especially in specialized domains with scarce examples. To alleviate these limitations, 
              our key idea is to reverse this process by synthesizing the question Q based on target answers A. We start with 
              target answers A derived from the tabular data D and generate corresponding statistical questions Q. This approach 
              ensures precise alignment between questions and answers, enabling more efficient dataset construction.
      
              To implement this, we design an efficient pipeline for constructing StatQA, as shown in Figure below. Unlike traditional methods, 
              we set target answers A based on tabular data D and then synthesize statistical questions Q in reverse. To ensure alignment 
              between Q and A, we incorporate automated prerequisite checks. To support the evaluation of statistical literacy, the target 
              answers A include relevant columns C and applicable statistical methods M, enabling the derivation of computational results R. 
              Therefore, our pipeline can synthesize numerous examples of (D, C, M, Q, R) along with other supplementary information.
            </md-block>
            <p>&ensp;</p>
            <div class="container is-max-desktop">
              <img id="teaser" autoplay muted loop playsinline height="90%" src="static\images\benchmark_example.png"/>
              <h5 class="subtitle has-text-centered">
                An Example in StatQA
              </h5>
            </div>
            <div class="container is-max-desktop">
              <img id="teaser" autoplay muted loop playsinline height="90%" src="static\images\distribution.png"/>
              <h5 class="subtitle has-text-centered">
                The Proportion of Statistical Tasks in StatQA
              </h5>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Experiments -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
    <div class="column is-centered">
      <h2 class="title is-2">Experiments</h2>
      <p>&ensp;</p>
      <div class="columns is-centered">
        <div class="content has-text-justified">
          <md-block>
            <strong>Experimental Protocols.</strong> We design experiments for LLMs similar to human statisticians' mindset,
            to evaluate the abilities of LLMs in statistical tasks. In the experiment, the LLMs need to pick
            headers of relevant data columns, assess the methods' applicability, and select all statistical methods
            that fit the usage scenario and prerequisites as statisticians, then respond in a specific format. In the human 
            experiments, we use the same protocol for consistency and develop a testing platform to facilitate participant selection.
            
            
            <strong>Metrics.</strong> Accuracy of relevant data columns and applicable methods selections, noted as Acc(C,M),
            is used as our metrics to evaluate if LLMs or participants truly understand the question and the
            applicability of statistical methods. Acc(C,M) refers to the proportion of methods and column
            selections fully aligned with the ground truth without any omissions or incorrect selections.

            
            <strong>Results.</strong> We evaluate the performance of LLMs and compare it with human performance. The figures below show 
            the best experimental results for each model, as well as a stacked histogram for error analysis. <strong><em>For full results and detailed 
            analysis, please refer to our paper.</em></strong>
          </md-block>
          <p>&ensp;</p>
          <div class="container is-max-desktop">
            <img id="teaser" autoplay muted loop playsinline height="90%" src="static\images\radar.png"/>
            <h5 class="subtitle has-text-centered">
              Best Results of Each Model in Sub-tasks.
            </h5>
          </div>
          <div class="container is-max-desktop">
            <img id="teaser" autoplay muted loop playsinline height="90%"src="static\images\error_bar_chart.png"/>
            <h5 class="subtitle has-text-centered">
              Distribution of Error Categories Across Experiments
            </h5>
          </div>
        </div>
      </div>
    </div>
  </div>
  </div>
</section>


<!-- Findins -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
    <div class="column is-centered">
      <h2 class="title is-2">Findings and Take-aways</h2>
      <p>&ensp;</p>
      <div class="columns is-centered">
        <div class="content has-text-justified">
          <!-- <p>We summarize six key findings through our systematic experiments and analysis:</p> -->
          <md-block>
            We summarize six key findings through our systematic experiments and analysis:
            - Few-shot learning and the inclusion of domain knowledge are helpful for LLMs in this
            task, whereas CoT is more likely to result in slight performance degradation in smaller models.
            - LLMs with prompt-based approaches remain behind people in statistics. However, the
            gap can be filled even surpassed by fine-tuning or introducing domain knowledge to a strong LLM.
            - Humans and most LLMs are adept at descriptive statistics tasks but struggle with
            contingency table and variance tests. Domain knowledge significantly boosts larger proprietary
            LLMs' performance, notably GPT-4o, but has limited impact on smaller open-source models.
            - LLaMA-3 and GPT models demonstrate a competent understanding of tasks and the
            latter can accurately select data columns, but LLaMA-2 models have difficulties in these aspects.
            - LLMs are good at distinguishing different statistical tasks then selecting associated
            methods but struggle to utilize the domain knowledge to assess method applicability effectively.
            Conversely, humans excel at discerning method applicability but are prone to task confusion.
            - Humans and LLMs have distinct proficiencies and weaknesses in different aspects of
            selecting applicable statistical tasks, highlighting the potential for complementary collaboration.
          </md-block>
          <p>&ensp;</p>
        </div>
      </div>
    </div>
  </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <p>If you find our work useful or inspiring, please kindly cite:</p>
    <pre><code>@inproceedings{zhu2024statqa,
      author = {Zhu, Yizhang and Du, Shiyin and Li, Boyan and Luo, Yuyu and Tang, Nan},
      booktitle = {Advances in Neural Information Processing Systems},
      editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
      pages = {62697--62731},
      publisher = {Curran Associates, Inc.},
      title = {Are Large Language Models Good Statisticians?},
      url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/729786203d330da046dd8091c2d92a66-Paper-Datasets_and_Benchmarks_Track.pdf},
      volume = {37},
      year = {2024}
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="visit_map" style="width: 500px; margin: 0 auto 30px;">
    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=eZtyFmCLWjLSTolBvPncsxCAeFBd1zpkuPucgYF1Q8M'></script>
  </div>
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/pdf/2406.07815">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/HKUSTDial" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
